import json
import shutil
import html
import tempfile
from pathlib import Path
from urllib.request import urlretrieve
from typing import List, Dict, Any
import io
import sys
import re
import mimetypes
import base64

from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS

try:
    import torch  # type: ignore
except ImportError:
    torch = None

try:
    import whisper  # type: ignore
except ImportError:  # Whisper is optional for local/offline use
    whisper = None

# æ–‡æœ¬å¤„ç†åº“
try:
    import PyPDF2  # type: ignore
except ImportError:
    PyPDF2 = None

try:
    import epub  # type: ignore
except ImportError:
    epub = None

try:
    from ebooklib import epub as ebooklib_epub  # type: ignore
except ImportError:
    ebooklib_epub = None

app = Flask(
    __name__,
    static_folder=str(Path(__file__).parent.parent / "static"),
    static_url_path="/static"
)
CORS(app)
# å…è®¸ä¸Šä¼ è¾ƒå¤§æ–‡ä»¶ï¼ˆé»˜è®¤æ— é™åˆ¶ï¼Œè¿™é‡Œè®¾ç½®ä¸Šé™ 512MB ä»¥é˜²æ„å¤– 413ï¼‰
app.config["MAX_CONTENT_LENGTH"] = 512 * 1024 * 1024

# --- User/Data/Config Directories -----------------------------------------
USER_DATA_DIR = Path(__file__).parent.parent / "user_data"
CONFIG_DIR = Path(__file__).parent.parent / "config"
MODELS_DIR = Path(__file__).parent.parent / "models"
USER_DATA_DIR.mkdir(exist_ok=True)

def get_user_file_path(filename: str, subdir: str = "") -> Path:
    """è·å–ç”¨æˆ·æ•°æ®æ–‡ä»¶è·¯å¾„"""
    if subdir:
        target_dir = USER_DATA_DIR / subdir
        target_dir.mkdir(exist_ok=True)
        return target_dir / filename
    return USER_DATA_DIR / filename


# --- Whisper helpers -------------------------------------------------------

_model_cache = None
_ffmpeg_available = None
_device = None
_transcribe_progress = {"status": "", "progress": 0}

def get_device():
    """Get the device to use for inference (GPU or CPU)."""
    global _device
    if _device is not None:
        return _device
    
    if torch is not None and torch.cuda.is_available():
        _device = "cuda"
        print(f"ğŸš€ CUDA GPU available! Using GPU for inference.")
        print(f"   Device: {torch.cuda.get_device_name(0)}")
        print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        _device = "cpu"
        if torch is None:
            print("âš ï¸  PyTorch not installed, using CPU")
        else:
            print("â„¹ï¸  No CUDA GPU available, using CPU")
    
    return _device

def check_ffmpeg():
    """Check if FFmpeg is available in the system."""
    global _ffmpeg_available
    if _ffmpeg_available is not None:
        return _ffmpeg_available
    _ffmpeg_available = shutil.which("ffmpeg") is not None
    if not _ffmpeg_available:
        print("âš ï¸  WARNING: FFmpeg not found! Audio transcription will fail.")
        print("   Please install FFmpeg: https://ffmpeg.org/download.html")
        print("   Windows: winget install Gyan.FFmpeg")
    return _ffmpeg_available

def get_model():
    """Lazily load Whisper model; return None if unavailable."""
    global _model_cache
    if _model_cache is not None:
        return _model_cache
    if whisper is None:
        return None
    
    device = get_device()
    
    # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶ï¼ˆæ”¯æŒ active_model.txt æŒ‡å®šï¼‰
    model_files = sorted(MODELS_DIR.glob("*.pt")) if MODELS_DIR.exists() else []
    
    if model_files:
        # ä½¿ç”¨æ¿€æ´»çš„æ¨¡å‹ï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œå¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ª
        active_path = CONFIG_DIR / "active_model.txt"
        chosen = None
        if active_path.exists():
            name = active_path.read_text().strip()
            candidate = MODELS_DIR / name
            if candidate.exists():
                chosen = candidate
        model_path = chosen if chosen is not None else model_files[0]
        print(f"Loading local model: {model_path.name}")
        _model_cache = whisper.load_model(str(model_path), device=device)
    else:
        # å›é€€åˆ°è‡ªåŠ¨ä¸‹è½½æ¨¡å¼
        env_path = CONFIG_DIR / ".env"
        model_name = env_path.read_text().strip() if env_path.exists() else "base"
        print(f"Downloading model: {model_name}")
        _model_cache = whisper.load_model(model_name, device=device)
    
    return _model_cache

# --- Model management APIs -------------------------------------------------

MODEL_URLS = {
    "tiny": "https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt",
    "base": "https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt",
    "small": "https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt",
    "medium": "https://openaipublic.azureedge.net/main/whisper/models/345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1/medium.pt",
    "large": "https://openaipublic.azureedge.net/main/whisper/models/e4b87e7e0bf463eb8e6956e646f1e277e901512310def2c24bf0e11bd3c28e9a/large.pt",
}

def list_local_models():
    items = []
    if MODELS_DIR.exists():
        for m in MODELS_DIR.glob("*.pt"):
            items.append({
                "filename": m.name,
                "size_mb": round(m.stat().st_size / (1024 * 1024), 1)
            })
    return items

@app.get('/api/models/list')
def api_models_list():
    local = list_local_models()
    current = None
    active_path = CONFIG_DIR / "active_model.txt"
    if active_path.exists():
        current = active_path.read_text().strip()
    elif local:
        current = local[0]["filename"]
    else:
        env_path = CONFIG_DIR / ".env"
        current = env_path.read_text().strip() if env_path.exists() else None
    return {"status": "success", "local": local, "current": current, "canSwitch": len(local) > 1}

@app.post('/api/models/download')
def api_models_download():
    data = request.get_json(silent=True) or {}
    name = str(data.get('name', 'base')).lower()
    if name not in MODEL_URLS:
        return {"status": "error", "message": "unknown model"}, 400
    MODELS_DIR.mkdir(exist_ok=True)
    target = MODELS_DIR / f"{name}.pt"
    try:
        url = MODEL_URLS[name]
        urlretrieve(url, target)
        return {"status": "success", "filename": target.name}
    except Exception as e:
        return {"status": "error", "message": str(e)}, 500

@app.post('/api/models/set_active')
def api_models_set_active():
    data = request.get_json(silent=True) or {}
    filename = data.get('filename')
    if not filename:
        return {"status": "error", "message": "filename required"}, 400
    candidate = MODELS_DIR / filename
    if not candidate.exists():
        return {"status": "error", "message": "file not found"}, 404
    CONFIG_DIR.mkdir(exist_ok=True)
    (CONFIG_DIR / 'active_model.txt').write_text(filename)
    # æ¸…ç†ç¼“å­˜ä»¥ä¾¿ä¸‹æ¬¡åŠ è½½æ–°æ¨¡å‹
    global _model_cache
    _model_cache = None
    return {"status": "success", "active": filename}


def run_whisper_transcribe(tmp_path: Path, language: str | None = None) -> Dict[str, Any]:
    global _transcribe_progress
    model = get_model()
    if model is None:
        return {"text": "", "segments": []}
    if not check_ffmpeg():
        raise RuntimeError(
            "FFmpeg is not installed. Please install FFmpeg to use audio transcription. "
            "See INSTALL_FFMPEG.md for installation instructions."
        )
    
    print(f"ğŸ”„ Starting transcription: {tmp_path.name}")
    _transcribe_progress = {"status": "åŠ è½½ä¸­...", "progress": 5}
    
    # æ•è·è¿›åº¦è¾“å‡º
    old_stdout = sys.stdout
    progress_capture = io.StringIO()
    
    try:
        sys.stdout = progress_capture
        result = model.transcribe(str(tmp_path), language=language, verbose=False)
    finally:
        sys.stdout = old_stdout
    
    # è§£æè¿›åº¦ä¿¡æ¯
    progress_output = progress_capture.getvalue()
    if "Detected language" in progress_output:
        for line in progress_output.split('\n'):
            if "Detected language" in line:
                _transcribe_progress["detected_lang"] = line.strip()
                print(f"ğŸŒ {line.strip()}")
    
    _transcribe_progress["status"] = f"å¤„ç†ä¸­ ({len(result.get('segments', []))} ä¸ªç‰‡æ®µ)"
    _transcribe_progress["progress"] = 90
    
    print(f"âœ… Transcription complete: {len(result.get('segments', []))} segments")
    
    segments = [
        {
            "start": float(seg.get("start", 0)),
            "end": float(seg.get("end", 0)),
            "text": seg.get("text", "").strip(),
        }
        for seg in result.get("segments", [])
    ]
    
    _transcribe_progress["status"] = "å®Œæˆ"
    _transcribe_progress["progress"] = 100
    
    return {"text": result.get("text", ""), "segments": segments}


# --- Document Processing Helpers -------------------------------------------

def extract_text_from_pdf(file_path: str) -> str:
    """ä»PDFæ–‡ä»¶æå–æ–‡æœ¬å¹¶ä»¥åˆ†é¡µHTMLå½¢å¼è¿”å›ï¼Œä¿æŒåŸæœ‰æ’ç‰ˆï¼ˆé€é¡µå±•ç¤ºï¼‰"""
    if PyPDF2 is None:
        raise ImportError("PyPDF2 not installed. Please install it: pip install PyPDF2")
    
    pages_html = []
    try:
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)
            for page_num in range(total_pages):
                page = pdf_reader.pages[page_num]
                text = page.extract_text() or ""
                # ä½¿ç”¨ <pre> ä¿ç•™æ¢è¡Œä¸ç©ºæ ¼ï¼ŒåŒ…è£…é¡µå®¹å™¨æ–¹ä¾¿åˆ†é¡µå±•ç¤º
                escaped = html.escape(text)
                page_html = (
                    f'<div class="pdf-page">'
                    f'<div class="page-number">ç¬¬ {page_num + 1} é¡µ / {total_pages}</div>'
                    f'<pre>{escaped}</pre>'
                    f'</div>'
                )
                pages_html.append(page_html)
    except Exception as e:
        raise Exception(f"PDFæå–é”™è¯¯: {str(e)}")
    
    return '\n'.join(pages_html)


def extract_text_from_epub(file_path: str) -> str:
    """ä»EPUBæ–‡ä»¶æå–æ–‡æœ¬å’ŒHTMLå†…å®¹"""
    if ebooklib_epub is None:
        raise ImportError("ebooklib not installed. Please install it: pip install ebooklib")
    
    text_content = []
    try:
        book = ebooklib_epub.read_epub(file_path)
        
        # é¦–å…ˆæå–å¹¶ä¿å­˜æ‰€æœ‰å›¾ç‰‡èµ„æº
        import hashlib
        import io
        
        epub_hash = hashlib.md5(file_path.encode()).hexdigest()[:8]
        images_dir = Path("static") / "reading_images" / epub_hash
        images_dir.mkdir(parents=True, exist_ok=True)
        
        image_mapping = {}  # æ˜ å°„ï¼šæ–‡ä»¶å -> æ–°URL
        
        # æ”¶é›†æ‰€æœ‰é¡¹ç›®ç”¨äºè°ƒè¯•
        all_items = list(book.get_items())
        print(f"âœ“ EPUBå…±æœ‰ {len(all_items)} ä¸ªé¡¹ç›®")
        
        # æ”¶é›†æ‰€æœ‰å›¾ç‰‡
        for item in all_items:
            item_type = item.get_type()
            item_name = item.get_name() if hasattr(item, 'get_name') else str(item)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡èµ„æº
            is_image = False
            
            # æ–¹æ³•1ï¼šæ£€æŸ¥ ITEM_IMAGE å¸¸é‡
            if hasattr(ebooklib_epub, 'ITEM_IMAGE'):
                is_image = item_type == ebooklib_epub.ITEM_IMAGE
            else:
                # æ–¹æ³•2ï¼šæ£€æŸ¥å…ƒç»„æ ¼å¼æˆ–æ•´æ•°å€¼
                if isinstance(item_type, tuple):
                    is_image = item_type[0] == 3  # IMAGE = (3, 'DOCUMENT_IMAGE')
                elif isinstance(item_type, int):
                    is_image = item_type == 3
            
            # æ–¹æ³•3ï¼šå¦‚æœåç§°åŒ…å«å›¾ç‰‡æ‰©å±•åï¼Œä¹Ÿè®¤ä¸ºæ˜¯å›¾ç‰‡
            if not is_image and item_name and any(item_name.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp']):
                is_image = True
                print(f"  âœ“ é€šè¿‡æ‰©å±•åæ£€æµ‹åˆ°å›¾ç‰‡: {item_name}")
            
            if is_image:
                try:
                    content = item.get_content()
                    item_name_safe = item.get_name() if item.get_name() else f"image_{len(image_mapping)}"
                    
                    # æå–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
                    filename = item_name_safe.split('/')[-1].split('\\\\')[-1]
                    
                    # ä¿å­˜å›¾ç‰‡
                    image_path = images_dir / filename
                    with open(image_path, 'wb') as f:
                        f.write(content)
                    
                    # å»ºç«‹æ˜ å°„ï¼šæ–‡ä»¶å -> URL
                    new_url = f"/static/reading_images/{epub_hash}/{filename}"
                    image_mapping[filename] = new_url
                    
                    print(f"âœ“ æå–å›¾ç‰‡: {filename} -> {new_url}")
                except Exception as e:
                    print(f"âœ— æå–å›¾ç‰‡å¤±è´¥ {item_name_safe}: {str(e)}")
                    pass
        
        # ç„¶åæå–æ–‡æ¡£å†…å®¹
        for item in all_items:
            item_type = item.get_type()
            is_document = False
            
            if hasattr(ebooklib_epub, 'ITEM_DOCUMENT'):
                is_document = item_type == ebooklib_epub.ITEM_DOCUMENT
            else:
                if isinstance(item_type, tuple):
                    is_document = item_type[0] == 9  # DOCUMENT = (9, 'DOCUMENT')
                elif isinstance(item_type, int):
                    is_document = item_type == 9
                else:
                    try:
                        item.get_content()
                        is_document = True
                    except:
                        is_document = False
            
            if is_document:
                try:
                    content = item.get_content()
                    html_text = content.decode('utf-8', errors='ignore')
                    
                    # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
                    html_text = re.sub(r'<head[^>]*>.*?</head>', '', html_text, flags=re.DOTALL | re.IGNORECASE)
                    html_text = re.sub(r'<script[^>]*>.*?</script>', '', html_text, flags=re.DOTALL | re.IGNORECASE)
                    html_text = re.sub(r'<style[^>]*>.*?</style>', '', html_text, flags=re.DOTALL | re.IGNORECASE)
                    html_text = re.sub(r'<meta[^>]*>', '', html_text, flags=re.IGNORECASE)
                    html_text = re.sub(r'<title[^>]*>.*?</title>', '', html_text, flags=re.DOTALL | re.IGNORECASE)
                    
                    # æ›¿æ¢å›¾ç‰‡è·¯å¾„ - å¤„ç†srcä¸­çš„ä»»ä½•å¼•ç”¨å›¾ç‰‡çš„è·¯å¾„
                    def replace_src(match):
                        src = match.group(1)
                        # è·å–æ–‡ä»¶å
                        img_filename = src.split('/')[-1].split('\\\\')[-1]
                        print(f"  å¤„ç†å›¾ç‰‡src: {src} -> æ–‡ä»¶å: {img_filename}, æ˜ å°„è¡¨å¤§å°: {len(image_mapping)}")
                        # æ£€æŸ¥æ˜¯å¦åœ¨æ˜ å°„ä¸­
                        if img_filename in image_mapping:
                            new_url = image_mapping[img_filename]
                            print(f"  âœ“ æ˜ å°„åˆ°: {new_url}")
                            return f'src="{new_url}"'
                        else:
                            print(f"  âœ— æœªæ‰¾åˆ°æ˜ å°„")
                        return match.group(0)  # ä¿ç•™åŸæ ·
                    
                    # æ›¿æ¢æ‰€æœ‰srcå±æ€§ï¼ˆå¤šç§æ ¼å¼ï¼‰
                    # æ ¼å¼1: src="..." æˆ– src='...'
                    html_text = re.sub(r'src\s*=\s*["\']([^"\']*)["\']', replace_src, html_text, flags=re.IGNORECASE)
                    # æ ¼å¼2: src=... (æ²¡æœ‰å¼•å·)
                    html_text = re.sub(r'src\s*=\s*([^\s>]+)', replace_src, html_text, flags=re.IGNORECASE)
                    
                    html_text = html_text.strip()
                    if html_text:
                        text_content.append(html_text)
                except Exception as e:
                    print(f"âœ— æå–æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}")
                    pass
    except Exception as e:
        raise Exception(f"EPUBæå–é”™è¯¯: {str(e)}")
    
    print(f"âœ“ EPUBæå–å®Œæˆï¼Œæ‰¾åˆ° {len(image_mapping)} å¼ å›¾ç‰‡ï¼Œ{len(text_content)} ä¸ªæ–‡æ¡£")
    return '\n'.join(text_content)


def extract_text_from_txt(file_path: str) -> str:
    """ä»TXTæ–‡ä»¶è¯»å–æ–‡æœ¬"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except UnicodeDecodeError:
        # å°è¯•å…¶ä»–ç¼–ç 
        with open(file_path, 'r', encoding='gbk') as file:
            return file.read()
    except Exception as e:
        raise Exception(f"TXTè¯»å–é”™è¯¯: {str(e)}")


def extract_text_from_doc(file_path: str) -> str:
    """ä»DOC/DOCXæå–æ–‡æœ¬ï¼Œå°½é‡æŒ‰é¡µå±•ç¤ºï¼šé‡åˆ°åˆ†é¡µç¬¦æ—¶æ¢é¡µï¼Œå¦åˆ™æŒ‰æ®µè½ç»„åˆ"""
    try:
        from docx import Document
        try:
            from docx.enum.text import WD_BREAK
        except Exception:
            WD_BREAK = None
    except ImportError:
        raise ImportError("python-docx not installed. Please install it: pip install python-docx")
    
    try:
        doc = Document(file_path)
        pages: list[list[str]] = [[]]
        for para in doc.paragraphs:
            text = para.text or ""
            # æ£€æµ‹æ®µå†…æ˜¯å¦å«åˆ†é¡µç¬¦
            has_page_break = False
            if WD_BREAK:
                for run in para.runs:
                    if getattr(run, "break_type", None) == WD_BREAK.PAGE:
                        has_page_break = True
                        break
            # å…ˆè®°å½•å½“å‰æ®µæ–‡æœ¬
            if text.strip():
                pages[-1].append(text)
            # å¦‚æœ‰åˆ†é¡µç¬¦ï¼Œå¼€å¯æ–°é¡µ
            if has_page_break:
                pages.append([])
        # æ”¶å°¾ç©ºé¡µæ¸…ç†
        pages = [p for p in pages if any(seg.strip() for seg in p)] or [[]]

        pages_html = []
        total_pages = len(pages)
        for idx, page in enumerate(pages, 1):
            escaped = html.escape('\n'.join(page))
            page_html = (
                f'<div class="doc-page">'
                f'<div class="page-number">ç¬¬ {idx} é¡µ / {total_pages}</div>'
                f'<pre>{escaped}</pre>'
                f'</div>'
            )
            pages_html.append(page_html)
        return '\n'.join(pages_html)
    except Exception as e:
        raise Exception(f"Wordæ–‡æ¡£æå–é”™è¯¯: {str(e)}")


def paginate_text(text: str, chars_per_page: int = 1500) -> List[str]:
    """å°†æ–‡æœ¬åˆ†é¡µ"""
    pages = []
    current_page = ""
    
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = text.split('\n')
    
    for para in paragraphs:
        if len(current_page) + len(para) + 1 > chars_per_page:
            if current_page:
                pages.append(current_page)
            current_page = para
        else:
            if current_page:
                current_page += '\n' + para
            else:
                current_page = para
    
    if current_page:
        pages.append(current_page)
    
    return pages if pages else [""]


def extract_words_from_text(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–å•è¯ï¼ˆä¿„è¯­ï¼‰"""
    # ä¿„è¯­å•è¯æ¨¡å¼ï¼šå­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ã€æ’‡å·
    pattern = r"[Ğ°-ÑĞ-Ğ¯Ñ‘Ğ\w'-]+"
    words = re.findall(pattern, text.lower())
    return list(set(words))  # å»é‡


def count_total_words(text: str) -> int:
    """è®¡ç®—æ–‡æœ¬ä¸­çš„æ€»è¯æ•°ï¼ˆæ‰€æœ‰è¯æ±‡ï¼ŒåŒ…æ‹¬é‡å¤ï¼‰
    
    è§„åˆ™ï¼š
    - ä¸­æ–‡ï¼šæŒ‰å­—ç¬¦è®¡æ•°ï¼ˆæ±‰å­—ï¼‰
    - ä¿„æ–‡å’Œå…¶ä»–ï¼šæŒ‰ç©ºæ ¼åˆ†è¯
    """
    if not text:
        return 0
    
    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆCJKï¼‰
    cjk_pattern = r"[\u4e00-\u9fff\u3400-\u4dbf]"  # æ±‰å­—èŒƒå›´
    cjk_chars = re.findall(cjk_pattern, text)
    cjk_count = len(cjk_chars)
    
    # å»é™¤ä¸­æ–‡å­—ç¬¦åçš„æ–‡æœ¬
    text_without_cjk = re.sub(cjk_pattern, " ", text)
    
    # ç»Ÿè®¡å…¶ä»–è¯­è¨€çš„è¯æ±‡ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼‰
    other_pattern = r"[Ğ°-ÑĞ-Ğ¯Ñ‘Ğ\w'-]+"
    other_words = re.findall(other_pattern, text_without_cjk)
    other_count = len(other_words)
    
    return cjk_count + other_count


# --- Scoring helpers -------------------------------------------------------

def sequence_similarity(reference: str, hypothesis: str) -> Dict[str, Any]:
    from difflib import SequenceMatcher

    matcher = SequenceMatcher(None, reference.lower(), hypothesis.lower())
    similarity = round(matcher.ratio() * 100, 2)

    ref_tokens = reference.split()
    hyp_tokens = hypothesis.split()
    token_mismatches: List[Dict[str, Any]] = []
    max_len = max(len(ref_tokens), len(hyp_tokens))
    for i in range(max_len):
        ref_tok = ref_tokens[i] if i < len(ref_tokens) else None
        hyp_tok = hyp_tokens[i] if i < len(hyp_tokens) else None
        if ref_tok != hyp_tok:
            token_mismatches.append({"index": i, "reference": ref_tok, "hypothesis": hyp_tok})

    return {"similarity": similarity, "mismatches": token_mismatches}


# --- Routes ----------------------------------------------------------------

@app.route("/api/health", methods=["GET"])
def health():
    return jsonify({
        "status": "ok",
        "whisper": whisper is not None,
        "ffmpeg": check_ffmpeg(),
        "gpu": get_device() == "cuda",
        "device": get_device()
    })


@app.route("/api/user-data/size", methods=["GET"])
def get_user_data_size():
    """è·å–ç”¨æˆ·æ•°æ®æ–‡ä»¶å¤¹çš„è¯¦ç»†å¤§å°ç»Ÿè®¡"""
    try:
        stats = {
            "media": 0,      # åª’ä½“æ–‡ä»¶
            "subtitles": 0,  # å­—å¹•æ–‡ä»¶
            "vocab": 0,      # ç”Ÿè¯æœ¬æ•°æ®
            "playlists": 0,  # æ’­æ”¾åˆ—è¡¨æ•°æ®
            "settings": 0,   # è®¾ç½®æ•°æ®
            "total": 0
        }
        
        print(f"[ç»Ÿè®¡æ•°æ®] user_data è·¯å¾„: {USER_DATA_DIR}")
        print(f"[ç»Ÿè®¡æ•°æ®] user_data å­˜åœ¨: {USER_DATA_DIR.exists()}")
        
        if USER_DATA_DIR.exists():
            for subdir, size_key in [
                ("media", "media"),
                ("subtitles", "subtitles"),
                ("vocab", "vocab"),
                ("playlists", "playlists"),
                ("settings", "settings")
            ]:
                subdir_path = USER_DATA_DIR / subdir
                if subdir_path.exists():
                    for item in subdir_path.rglob("*"):
                        if item.is_file():
                            file_size = item.stat().st_size
                            stats[size_key] += file_size
                            print(f"[ç»Ÿè®¡æ•°æ®] {subdir}/{item.name}: {file_size} bytes")
            
            # è®¡ç®—æ€»å¤§å°
            stats["total"] = sum(v for k, v in stats.items() if k != "total")
        
        print(f"[ç»Ÿè®¡æ•°æ®] æœ€ç»ˆç»Ÿè®¡: {stats}")
        
        # è½¬æ¢ä¸ºæ›´å‹å¥½çš„æ ¼å¼ï¼ˆbytesï¼‰
        return jsonify({
            "status": "success",
            "bytes": stats,
            "total_bytes": stats["total"],
            "total_kb": round(stats["total"] / 1024, 2)
        })
    except Exception as e:
        print(f"[ç»Ÿè®¡æ•°æ®] é”™è¯¯: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


@app.route("/api/transcribe/progress", methods=["GET"])
def get_transcribe_progress():
    """è·å–å®æ—¶è½¬å½•è¿›åº¦"""
    global _transcribe_progress
    return jsonify(_transcribe_progress)


@app.route("/api/transcribe", methods=["POST"])
def transcribe():
    global _transcribe_progress
    if "audio" not in request.files:
        return jsonify({"error": "audio file missing"}), 400
    language = request.form.get("language")
    audio_file = request.files["audio"]

    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.filename).suffix or ".wav") as tmp:
        audio_file.save(tmp.name)
        tmp_path = Path(tmp.name)

    try:
        _transcribe_progress = {"status": "å¼€å§‹è½¬å½•...", "progress": 0}
        result = run_whisper_transcribe(tmp_path, language)
        _transcribe_progress = {"status": "å®Œæˆ", "progress": 100}
        return jsonify({**result, "status": "success"})
    except Exception as e:
        _transcribe_progress = {"status": "é”™è¯¯", "progress": 0, "error": str(e)}
        return jsonify({"status": "error", "error": str(e)}), 500
    finally:
        tmp_path.unlink(missing_ok=True)


@app.route("/api/score", methods=["POST"])
def score():
    payload = request.get_json(force=True)
    reference = payload.get("reference", "")
    hypothesis = payload.get("hypothesis", "")
    if not reference:
        return jsonify({"error": "reference text required"}), 400
    metrics = sequence_similarity(reference, hypothesis)
    return jsonify(metrics)


@app.route("/api/subtitles/generate", methods=["POST"])
def generate_subtitles():
    global _transcribe_progress
    
    # æ”¯æŒä¸¤ç§æ–¹å¼ï¼šä¸Šä¼ æ–‡ä»¶ æˆ– ä½¿ç”¨å·²æœ‰çš„æ–‡ä»¶å
    audio_file = None
    tmp_path = None
    base_name = None
    
    if "audio" in request.files:
        # æ–¹å¼1ï¼šç›´æ¥ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
        audio_file = request.files["audio"]
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.filename).suffix or ".wav") as tmp:
            audio_file.save(tmp.name)
            tmp_path = Path(tmp.name)
        base_name = Path(audio_file.filename).stem
    elif "filename" in request.form:
        # æ–¹å¼2ï¼šä½¿ç”¨å·²å­˜åœ¨çš„æ–‡ä»¶åï¼ˆä»æ’­æ”¾åˆ—è¡¨ï¼‰
        filename = request.form.get("filename")
        
        # å°è¯•å¤šä¸ªä½ç½®æŸ¥æ‰¾æ–‡ä»¶ï¼ˆæ’­æ”¾åˆ—è¡¨ä¸­çš„æ–‡ä»¶åœ¨ user_data/mediaï¼‰
        possible_paths = [
            USER_DATA_DIR / "media" / filename,  # æ’­æ”¾åˆ—è¡¨ä¸­çš„åª’ä½“æ–‡ä»¶
            USER_DATA_DIR / filename,             # user_data æ ¹ç›®å½•
            Path("user_data") / "media" / filename,
            Path("user_data") / filename,
            Path("") / filename,  # å½“å‰ç›®å½•
        ]
        
        tmp_path = None
        for path in possible_paths:
            if path.exists():
                tmp_path = path
                break
        
        if tmp_path is None:
            return jsonify({"error": f"file not found: {filename}", "status": "error"}), 400
        
        base_name = Path(filename).stem
    else:
        return jsonify({"error": "audio file or filename missing", "status": "error"}), 400
    
    language = request.form.get("language")

    try:
        _transcribe_progress = {"status": "å¼€å§‹ç”Ÿæˆå­—å¹•...", "progress": 0}
        result = run_whisper_transcribe(tmp_path, language)
        subtitles = [
            {
                "start": seg.get("start", 0.0),
                "end": seg.get("end", 0.0),
                "en": seg.get("text", ""),
                "zh": "",
                "userEn": "",
                "userZh": "",
                "note": "",
            }
            for seg in result.get("segments", [])
        ]
        
        # ä¿å­˜ç”Ÿæˆçš„å­—å¹•åˆ°ç”¨æˆ·æ•°æ®æ–‡ä»¶å¤¹
        subtitle_path = get_user_file_path(f"{base_name}.json", "subtitles")
        with open(subtitle_path, "w", encoding="utf-8") as f:
            json.dump(subtitles, f, ensure_ascii=False, indent=2)
        print(f"âœ“ å­—å¹•å·²ä¿å­˜: {subtitle_path}")
        
        _transcribe_progress = {"status": "å®Œæˆ", "progress": 100}
        return jsonify({"subtitles": subtitles, "raw": result.get("text", ""), "status": "success"})
    except Exception as e:
        _transcribe_progress = {"status": "é”™è¯¯", "progress": 0, "error": str(e)}
        return jsonify({"status": "error", "error": str(e), "subtitles": [], "raw": ""}), 500
    finally:
        # åªåˆ é™¤é€šè¿‡ä¸Šä¼ åˆ›å»ºçš„ä¸´æ—¶æ–‡ä»¶
        if audio_file is not None and tmp_path is not None:
            tmp_path.unlink(missing_ok=True)


@app.route("/api/subtitles/save", methods=["POST"])
def save_subtitles():
    """ä¿å­˜ç”¨æˆ·ç¼–è¾‘çš„å­—å¹•"""
    try:
        payload = request.get_json(force=True)
        media_name = payload.get("mediaName", "untitled")
        subtitles = payload.get("subtitles", [])
        
        base_name = Path(media_name).stem
        subtitle_path = get_user_file_path(f"{base_name}.json", "subtitles")
        
        with open(subtitle_path, "w", encoding="utf-8") as f:
            json.dump(subtitles, f, ensure_ascii=False, indent=2)
        
        return jsonify({"status": "success", "path": str(subtitle_path)})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/subtitles/load/<filename>", methods=["GET"])
def load_subtitles(filename):
    """åŠ è½½ä¿å­˜çš„å­—å¹•æ–‡ä»¶"""
    try:
        base_name = Path(filename).stem
        subtitle_path = get_user_file_path(f"{base_name}.json", "subtitles")
        
        if subtitle_path.exists():
            with open(subtitle_path, "r", encoding="utf-8") as f:
                subtitles = json.load(f)
            return jsonify({"status": "success", "subtitles": subtitles})
        else:
            return jsonify({"status": "not_found", "subtitles": []}), 404
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/media/upload", methods=["POST"])
def upload_media():
    """ä¸Šä¼ åª’ä½“æ–‡ä»¶åˆ°æœåŠ¡å™¨"""
    try:
        if "media" not in request.files:
            return jsonify({"error": "media file missing", "status": "error"}), 400
        
        media_file = request.files["media"]
        if not media_file.filename:
            return jsonify({"error": "no filename", "status": "error"}), 400
        
        # ä¿å­˜åˆ° user_data/media æ–‡ä»¶å¤¹
        media_path = get_user_file_path(media_file.filename, "media")
        media_file.save(str(media_path))
        
        return jsonify({
            "status": "success",
            "path": str(media_path),
            "filename": media_file.filename
        })
    except Exception as e:
        # æ‰“å°è¯¦ç»†é”™è¯¯ä»¥ä¾¿å‰ç«¯æç¤º
        print(f"[upload_media] error: {e}")
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/media/load/<filename>", methods=["GET"])
def load_media(filename):
    """ä»æœåŠ¡å™¨åŠ è½½åª’ä½“æ–‡ä»¶"""
    try:
        media_path = get_user_file_path(filename, "media")
        
        if media_path.exists():
            return send_from_directory(
                media_path.parent,
                media_path.name,
                as_attachment=False
            )
        else:
            return jsonify({"status": "not_found"}), 404
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/vocab/save", methods=["POST"])
def save_vocab():
    """ä¿å­˜ç”Ÿè¯æœ¬æ•°æ®åˆ°æ–‡ä»¶ï¼ˆæ—§ç‰ˆAPIï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
    try:
        payload = request.get_json(force=True)
        vocab = payload.get("vocab", [])
        
        vocab_path = get_user_file_path("vocab.json", "vocab")
        
        with open(vocab_path, "w", encoding="utf-8") as f:
            json.dump(vocab, f, ensure_ascii=False, indent=2)
        
        return jsonify({"status": "success", "path": str(vocab_path)})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/vocab/load", methods=["GET"])
def load_vocab():
    """åŠ è½½ä¿å­˜çš„ç”Ÿè¯æœ¬æ•°æ®ï¼ˆæ—§ç‰ˆAPIï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
    try:
        vocab_path = get_user_file_path("vocab.json", "vocab")
        
        if vocab_path.exists():
            with open(vocab_path, "r", encoding="utf-8") as f:
                vocab = json.load(f)
            return jsonify({"status": "success", "vocab": vocab})
        else:
            return jsonify({"status": "success", "vocab": []})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e), "vocab": []}), 500


@app.route("/api/vocabbooks/save", methods=["POST"])
def save_vocabbooks():
    """ä¿å­˜å¤šä¸ªç”Ÿè¯æœ¬æ•°æ®åˆ°æ–‡ä»¶"""
    try:
        payload = request.get_json(force=True)
        vocabbooks = payload.get("vocabBooks", [])
        current_id = payload.get("currentVocabBookId", None)
        
        # ä¿å­˜ç”Ÿè¯æœ¬æ•°æ®
        vocabbooks_path = get_user_file_path("vocabbooks.json", "vocab")
        with open(vocabbooks_path, "w", encoding="utf-8") as f:
            json.dump({
                "vocabBooks": vocabbooks,
                "currentVocabBookId": current_id
            }, f, ensure_ascii=False, indent=2)
        
        return jsonify({"status": "success", "path": str(vocabbooks_path)})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/vocabbooks/load", methods=["GET"])
def load_vocabbooks():
    """åŠ è½½ä¿å­˜çš„å¤šä¸ªç”Ÿè¯æœ¬æ•°æ®"""
    try:
        vocabbooks_path = get_user_file_path("vocabbooks.json", "vocab")
        
        if vocabbooks_path.exists():
            with open(vocabbooks_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            return jsonify({
                "status": "success",
                "vocabBooks": data.get("vocabBooks", []),
                "currentVocabBookId": data.get("currentVocabBookId", None)
            })
        else:
            return jsonify({
                "status": "success",
                "vocabBooks": [],
                "currentVocabBookId": None
            })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e), "vocabBooks": [], "currentVocabBookId": None}), 500


@app.route("/api/playlists/save", methods=["POST"])
def save_playlists():
    """ä¿å­˜æ’­æ”¾åˆ—è¡¨æ•°æ®åˆ°æ–‡ä»¶"""
    try:
        payload = request.get_json(force=True)
        playlists = payload.get("playlists", [])
        current_id = payload.get("currentPlaylistId", None)
        
        # ä¿å­˜æ’­æ”¾åˆ—è¡¨æ•°æ®
        playlists_path = get_user_file_path("playlists.json", "playlists")
        with open(playlists_path, "w", encoding="utf-8") as f:
            json.dump({
                "playlists": playlists,
                "currentPlaylistId": current_id
            }, f, ensure_ascii=False, indent=2)
        
        return jsonify({"status": "success", "path": str(playlists_path)})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/playlists/load", methods=["GET"])
def load_playlists():
    """åŠ è½½ä¿å­˜çš„æ’­æ”¾åˆ—è¡¨æ•°æ®"""
    try:
        playlists_path = get_user_file_path("playlists.json", "playlists")
        
        if playlists_path.exists():
            with open(playlists_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            return jsonify({
                "status": "success",
                "playlists": data.get("playlists", []),
                "currentPlaylistId": data.get("currentPlaylistId", None)
            })
        else:
            return jsonify({
                "status": "success",
                "playlists": [],
                "currentPlaylistId": None
            })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e), "playlists": [], "currentPlaylistId": None}), 500


@app.route("/api/settings/save", methods=["POST"])
def save_settings():
    """ä¿å­˜ç”¨æˆ·è®¾ç½®åˆ°æ–‡ä»¶"""
    try:
        payload = request.get_json(force=True)
        settings = payload.get("settings", {})
        
        settings_path = get_user_file_path("settings.json", "settings")
        with open(settings_path, "w", encoding="utf-8") as f:
            json.dump(settings, f, ensure_ascii=False, indent=2)
        
        return jsonify({"status": "success", "path": str(settings_path)})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/settings/load", methods=["GET"])
def load_settings():
    """åŠ è½½ä¿å­˜çš„ç”¨æˆ·è®¾ç½®"""
    try:
        settings_path = get_user_file_path("settings.json", "settings")
        
        if settings_path.exists():
            with open(settings_path, "r", encoding="utf-8") as f:
                settings = json.load(f)
            return jsonify({"status": "success", "settings": settings})
        else:
            return jsonify({"status": "success", "settings": {}})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e), "settings": {}}), 500


# --- Reading Module Routes --------------------------------------------------


@app.route("/api/reading/test-pdf", methods=["GET"])
def test_pdf_endpoint():
    """æµ‹è¯•endpoint - è¿”å›ç®€å•å“åº”"""
    print("[test_pdf_endpoint] è¢«è°ƒç”¨")
    return jsonify({"status": "ok", "message": "Test endpoint working"})

@app.route("/api/reading/raw/<path:doc_id>", methods=["GET", "HEAD"])
def serve_raw_document(doc_id):
    """è¿”å›åŸå§‹æ–‡ä»¶æˆ–è½¬æ¢åçš„PDFï¼Œä¾›å‰ç«¯åŸæ ·å±•ç¤º"""
    try:
        import time
        start_time = time.time()
        from urllib.parse import unquote, quote
        
        # URLè§£ç æ–‡ä»¶å
        doc_id = unquote(doc_id)
        print(f"[serve_raw_document] å¼€å§‹å¤„ç† doc_id: {doc_id}", flush=True)
        
        doc_index_path = get_user_file_path("documents.json", "readings")
        documents = {}
        if doc_index_path.exists():
            with open(doc_index_path, 'r', encoding='utf-8') as f:
                documents = json.load(f)
        print(f"[serve_raw_document] å·²åŠ è½½documents.json, å…±{len(documents)}ä¸ªæ–‡æ¡£")

        # å°è¯•ç²¾ç¡®åŒ¹é…
        if doc_id not in documents:
            # å°è¯•ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
            doc_id_lower = doc_id.lower()
            for key in documents.keys():
                if key.lower() == doc_id_lower:
                    doc_id = key
                    break
            else:
                print(f"[serve_raw_document] âŒ æ–‡æ¡£ä¸å­˜åœ¨: {doc_id}")
                return jsonify({"status": "error", "error": f"æ–‡æ¡£ä¸å­˜åœ¨: {doc_id}"}), 404

        meta = documents[doc_id]
        filename = meta.get("filename", doc_id)
        ext = meta.get("ext", "")  
        converted_pdf = meta.get("converted_pdf")
        print(f"[serve_raw_document] æ‰¾åˆ°æ–‡æ¡£: filename={filename}, ext={ext}")

        base_dir = get_user_file_path("", "readings")

        # ä¼˜å…ˆä½¿ç”¨è½¬æ¢åçš„PDFï¼ˆç”¨äºWordä¿æŒæ ·å¼ï¼‰
        if converted_pdf:
            pdf_path = Path(converted_pdf)
            if pdf_path.exists():
                print(f"[serve_raw_document] ä½¿ç”¨è½¬æ¢åçš„PDF: {pdf_path}")
                response = send_file(
                    pdf_path, 
                    mimetype="application/pdf",
                    as_attachment=False,
                    conditional=True  # å¯ç”¨æ¡ä»¶è¯·æ±‚ï¼ˆIf-Modified-Sinceç­‰ï¼‰
                )
                response.headers["Accept-Ranges"] = "bytes"
                # ç§»é™¤Content-Dispositionä»¥é¿å…è§¦å‘ä¸‹è½½
                response.headers.pop("Content-Disposition", None)
                return response

        # å¦åˆ™è¿”å›åŸæ–‡ä»¶
        file_path = base_dir / filename
        if not file_path.exists():
            print(f"[serve_raw_document] âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return jsonify({"status": "error", "error": "æ–‡ä»¶å·²ä¸¢å¤±"}), 404

        file_size = file_path.stat().st_size
        print(f"[serve_raw_document] æ–‡ä»¶è·¯å¾„: {file_path}")
        print(f"[serve_raw_document] æ–‡ä»¶å¤§å°: {file_size} bytes ({file_size/1024/1024:.2f} MB)")

        guessed_type, _ = mimetypes.guess_type(file_path)
        # å¦‚æœæ— æ³•çŒœæµ‹MIMEç±»å‹ï¼Œæ ¹æ®æ‰©å±•åæ‰‹åŠ¨è®¾ç½®
        if not guessed_type:
            ext_lower = Path(file_path).suffix.lower()
            mime_map = {
                '.pdf': 'application/pdf',
                '.epub': 'application/epub+zip',
                '.txt': 'text/plain; charset=utf-8',
                '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                '.doc': 'application/msword'
            }
            guessed_type = mime_map.get(ext_lower, 'application/octet-stream')
        
        print(f"[serve_raw_document] MIME type: {guessed_type}")
        
        # å¯¹å¤§æ–‡ä»¶ä½¿ç”¨æµå¼ä¼ è¾“
        if file_size > 1024 * 1024:  # > 1MB
            print(f"[serve_raw_document] ä½¿ç”¨æµå¼ä¼ è¾“ï¼ˆæ–‡ä»¶>1MBï¼‰")
            
        response = send_file(
            file_path, 
            mimetype=guessed_type, 
            as_attachment=False,
            conditional=True,  # æ”¯æŒHTTPæ¡ä»¶è¯·æ±‚
            max_age=0  # ç¦ç”¨ç¼“å­˜
        )
        response.headers["Accept-Ranges"] = "bytes"
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        # ç§»é™¤Content-Dispositionä»¥é¿å…è§¦å‘ä¸‹è½½
        response.headers.pop("Content-Disposition", None)
        
        elapsed = time.time() - start_time
        print(f"[serve_raw_document] âœ… å®Œæˆ, è€—æ—¶ {elapsed:.2f}s")

        return response
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/upload-document", methods=["POST"])
def upload_document():
    """ä¸Šä¼ å¹¶è§£ææ–‡æ¡£ï¼ˆPDF, EPUB, TXT, DOCï¼‰"""
    try:
        if 'file' not in request.files:
            return jsonify({"status": "error", "error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({"status": "error", "error": "æ–‡ä»¶åä¸ºç©º"}), 400
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_dir = get_user_file_path("", "readings")
        temp_dir.mkdir(exist_ok=True)
        
        file_ext = Path(file.filename).suffix.lower()
        temp_path = temp_dir / file.filename
        file.save(str(temp_path))
        
        print(f"ğŸ“„ Processing document: {file.filename}")
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬
        text = ""
        if file_ext == ".pdf":
            text = extract_text_from_pdf(str(temp_path))
        elif file_ext == ".epub":
            text = extract_text_from_epub(str(temp_path))
        elif file_ext in [".txt"]:
            text = extract_text_from_txt(str(temp_path))
        elif file_ext == ".md":
            # Markdown æ–‡ä»¶ç›´æ¥è¯»å–ä¸ºæ–‡æœ¬ï¼ˆå‰ç«¯ç”¨ marked.js è§£æï¼‰
            with open(temp_path, 'r', encoding='utf-8') as f:
                text = f.read()
        elif file_ext in [".doc", ".docx"]:
            text = extract_text_from_doc(str(temp_path))
        else:
            return jsonify({"status": "error", "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}"}), 400
        
        # ä¸å†è‡ªåŠ¨åˆ†é¡µï¼Œä¿å­˜å®Œæ•´æ–‡æœ¬
        # å¦‚æœéœ€è¦ï¼Œå‰ç«¯å¯ä»¥æ ¹æ®æ»šåŠ¨ä½ç½®è®¡ç®—é˜…è¯»è¿›åº¦
        
        # ç”Ÿæˆdoc_id
        doc_id = file.filename.replace(' ', '_').replace('.', '_')

        # è‹¥ä¸º Wordï¼Œå°è¯•è½¬æ¢ä¸º PDF ä»¥ä¿ç•™æ ·å¼ï¼ˆéœ€ docx2pdfï¼Œå¯èƒ½åœ¨æ—  Office ç¯å¢ƒä¸‹å¤±è´¥ï¼‰
        converted_pdf_path = None
        if file_ext in [".doc", ".docx"]:
            try:
                from docx2pdf import convert  # type: ignore
                out_pdf = get_user_file_path(f"{doc_id}.pdf", "readings")
                convert(str(temp_path), str(out_pdf))
                if out_pdf.exists():
                    converted_pdf_path = out_pdf
                    print(f"âœ“ Word è½¬ PDF æˆåŠŸ: {out_pdf}")
            except Exception as conv_err:
                print(f"âœ— Word è½¬ PDF å¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬æå–: {conv_err}")

        # ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®
        total_words = count_total_words(text)
        doc_metadata = {
            "filename": file.filename,
            "size": len(text),
            "char_count": len(text),
            "total_words": total_words,
            "upload_time": str(Path(temp_path).stat().st_mtime),
            "ext": file_ext,
            "converted_pdf": str(converted_pdf_path) if converted_pdf_path else None
        }
        
        # ä¿å­˜åˆ°JSON
        doc_index_path = get_user_file_path("documents.json", "readings")
        documents = {}
        if doc_index_path.exists():
            with open(doc_index_path, 'r', encoding='utf-8') as f:
                documents = json.load(f)
        
        documents[doc_id] = doc_metadata
        
        with open(doc_index_path, 'w', encoding='utf-8') as f:
            json.dump(documents, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜å®Œæ•´æ–‡æœ¬å†…å®¹ï¼ˆç”¨äºæ£€ç´¢/ç»Ÿè®¡ï¼›å±•ç¤ºä»ä½¿ç”¨åŸæ–‡ä»¶æˆ–è½¬æ¢åçš„PDFï¼‰
        content_path = get_user_file_path(f"{doc_id}_content.json", "readings")
        with open(content_path, 'w', encoding='utf-8') as f:
            json.dump({"text": text}, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            "status": "success",
            "doc_id": doc_id,
            "filename": file.filename,
            "char_count": len(text),
            "total_words": total_words,
            "size": len(text),
            "sample": text[:500],  # è¿”å›å‰500å­—ä½œä¸ºé¢„è§ˆ
            "view_url": f"/api/reading/raw/{doc_id}"
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/load-document/<doc_id>", methods=["GET"])
def load_document(doc_id):
    """åŠ è½½æŒ‡å®šæ–‡æ¡£çš„å†…å®¹"""
    try:
        content_path = get_user_file_path(f"{doc_id}_content.json", "readings")
        doc_index_path = get_user_file_path("documents.json", "readings")
        documents = {}
        if doc_index_path.exists():
            with open(doc_index_path, 'r', encoding='utf-8') as f:
                documents = json.load(f)
        
        if not content_path.exists():
            return jsonify({"status": "error", "error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404
        
        with open(content_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        text = data.get("text", "")
        
        # è®¡ç®—æ€»è¯æ•°
        total_words = count_total_words(text)
        
        return jsonify({
            "status": "success",
            "text": text,
            "char_count": len(text),
            "total_words": total_words,
            "view_url": f"/api/reading/raw/{doc_id}",
            "metadata": documents.get(doc_id, {})
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/delete-document/<doc_id>", methods=["DELETE"])
def delete_document(doc_id):
    """åˆ é™¤æŒ‡å®šæ–‡æ¡£åŠå…¶ç›¸å…³æ–‡ä»¶ï¼ˆå†…å®¹ã€ç¬”è®°ã€åŸæ–‡ä»¶ã€æå–å›¾ç‰‡ã€è½¬æ¢åçš„PDFï¼‰"""
    try:
        import hashlib

        doc_index_path = get_user_file_path("documents.json", "readings")
        documents = {}
        if doc_index_path.exists():
            with open(doc_index_path, 'r', encoding='utf-8') as f:
                documents = json.load(f)

        if doc_id not in documents:
            return jsonify({"status": "error", "error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404

        filename = documents[doc_id].get("filename", doc_id)
        converted_pdf = documents[doc_id].get("converted_pdf")

        # ä»ç´¢å¼•ä¸­ç§»é™¤å¹¶ä¿å­˜
        documents.pop(doc_id, None)
        with open(doc_index_path, 'w', encoding='utf-8') as f:
            json.dump(documents, f, ensure_ascii=False, indent=2)

        removed_files = []

        def remove_path(path: Path):
            if path.exists():
                try:
                    if path.is_dir():
                        shutil.rmtree(path, ignore_errors=True)
                    else:
                        path.unlink()
                    removed_files.append(str(path))
                except Exception:
                    pass

        base_dir = get_user_file_path("", "readings")
        file_path = base_dir / filename

        # ç›¸å…³æ–‡ä»¶è·¯å¾„
        content_path = get_user_file_path(f"{doc_id}_content.json", "readings")
        notes_path = get_user_file_path(f"{doc_id}_notes.json", "readings")
        converted_pdf_path = Path(converted_pdf) if converted_pdf else None

        # EPUB å›¾ç‰‡ç›®å½•ï¼ˆä¸æå–æ—¶ä¸€è‡´çš„ hash è§„åˆ™ï¼‰
        epub_hash = hashlib.md5(str(file_path).encode()).hexdigest()[:8]
        images_dir = Path("static") / "reading_images" / epub_hash

        # åˆ é™¤æ–‡ä»¶/ç›®å½•
        for p in [file_path, content_path, notes_path, images_dir, converted_pdf_path]:
            if p:
                remove_path(Path(p))

        return jsonify({
            "status": "success",
            "removed": removed_files
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/documents", methods=["GET"])
def list_documents():
    """åˆ—å‡ºæ‰€æœ‰å·²åŠ è½½çš„æ–‡æ¡£"""
    try:
        doc_index_path = get_user_file_path("documents.json", "readings")
        
        documents = {}
        if doc_index_path.exists():
            with open(doc_index_path, 'r', encoding='utf-8') as f:
                documents = json.load(f)
        
        return jsonify({
            "status": "success",
            "documents": documents
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/save-notes/<doc_id>", methods=["POST"])
def save_reading_notes(doc_id):
    """ä¿å­˜é˜…è¯»ç¬”è®°"""
    try:
        payload = request.get_json(force=True)
        notes = payload.get("notes", [])
        
        notes_path = get_user_file_path(f"{doc_id}_notes.json", "readings")
        with open(notes_path, 'w', encoding='utf-8') as f:
            json.dump(notes, f, ensure_ascii=False, indent=2)
        
        return jsonify({"status": "success", "path": str(notes_path)})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/load-notes/<doc_id>", methods=["GET"])
def load_reading_notes(doc_id):
    """åŠ è½½é˜…è¯»ç¬”è®°"""
    try:
        notes_path = get_user_file_path(f"{doc_id}_notes.json", "readings")
        
        notes = []
        if notes_path.exists():
            with open(notes_path, 'r', encoding='utf-8') as f:
                notes = json.load(f)
        
        return jsonify({
            "status": "success",
            "notes": notes
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/extract-words/<doc_id>", methods=["GET"])
def extract_document_words(doc_id):
    """ä»æ–‡æ¡£ä¸­æå–è¯æ±‡å¹¶è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
    try:
        content_path = get_user_file_path(f"{doc_id}_content.json", "readings")
        
        if not content_path.exists():
            return jsonify({"status": "error", "error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404
        
        with open(content_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        text = data.get("text", "")
        words = extract_words_from_text(text)
        
        # è®¡ç®—è¯é¢‘
        word_count = {}
        for word in words:
            word_count[word] = text.lower().count(word)
        
        # æŒ‰é¢‘ç‡æ’åº
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        
        # è®¡ç®—æ€»è¯æ•°
        total_words = count_total_words(text)
        
        return jsonify({
            "status": "success",
            "words": [{"word": w, "count": c} for w, c in sorted_words[:100]],
            "total_unique": len(words),
            "total_words": total_words,
            "text_length": len(text)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/reading/search/<doc_id>", methods=["POST"])
def search_in_document(doc_id):
    """åœ¨æ–‡æ¡£ä¸­æœç´¢æ–‡æœ¬"""
    try:
        payload = request.get_json(force=True)
        query = payload.get("query", "").lower()
        
        if not query:
            return jsonify({"status": "error", "error": "æœç´¢è¯ä¸ºç©º"}), 400
        
        content_path = get_user_file_path(f"{doc_id}_content.json", "readings")
        
        if not content_path.exists():
            return jsonify({"status": "error", "error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404
        
        with open(content_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        text = data.get("text", "")
        text_lower = text.lower()
        
        results = []
        pos = 0
        while True:
            idx = text_lower.find(query, pos)
            if idx == -1:
                break
            
            # è·å–ä¸Šä¸‹æ–‡
            context_start = max(0, idx - 50)
            context_end = min(len(text), idx + len(query) + 50)
            context = text[context_start:context_end]
            
            # è®¡ç®—å­—ç¬¦ä½ç½®ç™¾åˆ†æ¯”
            char_percent = round((idx / len(text)) * 100) if len(text) > 0 else 0
            
            results.append({
                "position": idx,
                "char_percent": char_percent,
                "context": context
            })
            pos = idx + 1
        
        return jsonify({
            "status": "success",
            "query": query,
            "results": results,
            "count": len(results)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


# ============================================================================
# PDFç¼“å­˜API - ä¿å­˜å’ŒåŠ è½½PDFæ¸²æŸ“æ•°æ®ï¼Œé¿å…é‡å¤æ¸²æŸ“
# ============================================================================

PDF_CACHE_DIR = Path(__file__).parent.parent / "user_data" / "pdf_cache"

def get_pdf_cache_path(pdf_filename: str) -> Path:
    """è·å–PDFç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    PDF_CACHE_DIR.mkdir(parents=True, exist_ok=True)
    # ä½¿ç”¨PDFæ–‡ä»¶åï¼ˆå»é™¤è·¯å¾„ï¼‰ä½œä¸ºç¼“å­˜æ–‡ä»¶å
    cache_filename = Path(pdf_filename).stem + ".cache.json"
    return PDF_CACHE_DIR / cache_filename


@app.route("/api/pdf-cache/save", methods=["POST"])
def save_pdf_cache():
    """ä¿å­˜PDFæ¸²æŸ“æ•°æ®åˆ°ç¼“å­˜
    
    è¯·æ±‚ä½“:
    {
        "pdfFilename": "example.pdf",  # PDFæ–‡ä»¶åï¼ˆç”¨äºè¯†åˆ«ç¼“å­˜ï¼‰
        "currentPage": 5,               # å½“å‰é¡µç 
        "scale": 1.2,                   # ç¼©æ”¾çº§åˆ«ï¼ˆæ•°å­—æˆ–'auto', 'fit-width', 'fit-page'ï¼‰
        "scrollTop": 1024,              # æ»šåŠ¨ä½ç½®
        "displayMode": "continuous"     # æ˜¾ç¤ºæ¨¡å¼
    }
    """
    try:
        data = request.get_json()
        pdf_filename = data.get("pdfFilename", "")
        
        if not pdf_filename:
            return jsonify({"status": "error", "message": "pdfFilename is required"}), 400
        
        cache_path = get_pdf_cache_path(pdf_filename)
        
        # å‡†å¤‡ç¼“å­˜æ•°æ®
        cache_data = {
            "pdfFilename": pdf_filename,
            "currentPage": data.get("currentPage", 1),
            "scale": data.get("scale", "auto"),
            "scrollTop": data.get("scrollTop", 0),
            "displayMode": data.get("displayMode", "continuous"),
            "timestamp": int(__import__("time").time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
        }
        
        # å†™å…¥ç¼“å­˜æ–‡ä»¶
        with open(cache_path, "w", encoding="utf-8") as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            "status": "success",
            "message": f"PDF cache saved for {pdf_filename}",
            "cachePath": str(cache_path)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/pdf-cache/load", methods=["POST"])
def load_pdf_cache():
    """åŠ è½½PDFæ¸²æŸ“ç¼“å­˜
    
    è¯·æ±‚ä½“:
    {
        "pdfFilename": "example.pdf"
    }
    
    è¿”å›ç¼“å­˜çš„é¡µé¢ã€ç¼©æ”¾ã€æ»šåŠ¨ä½ç½®ç­‰ä¿¡æ¯
    """
    try:
        data = request.get_json()
        pdf_filename = data.get("pdfFilename", "")
        
        if not pdf_filename:
            return jsonify({"status": "error", "message": "pdfFilename is required"}), 400
        
        cache_path = get_pdf_cache_path(pdf_filename)
        
        # å¦‚æœç¼“å­˜å­˜åœ¨ï¼Œè¯»å–å¹¶è¿”å›
        if cache_path.exists():
            with open(cache_path, "r", encoding="utf-8") as f:
                cache_data = json.load(f)
            
            return jsonify({
                "status": "success",
                "found": True,
                "cache": cache_data
            })
        else:
            return jsonify({
                "status": "success",
                "found": False,
                "cache": None,
                "message": "No cache found for this PDF"
            })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/pdf-cache/delete", methods=["POST"])
def delete_pdf_cache():
    """åˆ é™¤PDFæ¸²æŸ“ç¼“å­˜
    
    è¯·æ±‚ä½“:
    {
        "pdfFilename": "example.pdf"
    }
    """
    try:
        data = request.get_json()
        pdf_filename = data.get("pdfFilename", "")
        
        if not pdf_filename:
            return jsonify({"status": "error", "message": "pdfFilename is required"}), 400
        
        cache_path = get_pdf_cache_path(pdf_filename)
        
        if cache_path.exists():
            cache_path.unlink()
            return jsonify({
                "status": "success",
                "message": f"Cache deleted for {pdf_filename}"
            })
        else:
            return jsonify({
                "status": "success",
                "message": "No cache found to delete"
            })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/pdf-cache/list", methods=["GET"])
def list_pdf_cache():
    """åˆ—å‡ºæ‰€æœ‰PDFç¼“å­˜"""
    try:
        if not PDF_CACHE_DIR.exists():
            return jsonify({
                "status": "success",
                "caches": []
            })
        
        caches = []
        for cache_file in PDF_CACHE_DIR.glob("*.cache.json"):
            with open(cache_file, "r", encoding="utf-8") as f:
                cache_data = json.load(f)
            caches.append(cache_data)
        
        return jsonify({
            "status": "success",
            "caches": caches,
            "count": len(caches)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


# ============================================================================
# é€šç”¨æ–‡æ¡£é˜…è¯»è¿›åº¦API - ä¿å­˜æ‰€æœ‰æ–‡æ¡£ç±»å‹çš„é˜…è¯»è¿›åº¦
# ============================================================================

DOC_PROGRESS_DIR = Path(__file__).parent.parent / "user_data" / "doc_progress"

def get_doc_progress_path(doc_id: str) -> Path:
    """è·å–æ–‡æ¡£è¿›åº¦æ–‡ä»¶è·¯å¾„"""
    DOC_PROGRESS_DIR.mkdir(parents=True, exist_ok=True)
    # ä½¿ç”¨æ–‡æ¡£IDï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰ä½œä¸ºè¿›åº¦æ–‡ä»¶å
    safe_id = "".join(c if c.isalnum() or c in ('-', '_') else '_' for c in doc_id)
    progress_filename = safe_id + ".progress.json"
    return DOC_PROGRESS_DIR / progress_filename


@app.route("/api/doc-progress/save", methods=["POST"])
def save_doc_progress():
    """ä¿å­˜æ–‡æ¡£é˜…è¯»è¿›åº¦
    
    è¯·æ±‚ä½“:
    {
        "docId": "document-id",           # æ–‡æ¡£å”¯ä¸€IDï¼ˆå¿…éœ€ï¼‰
        "docType": "pdf|epub|docx|txt",  # æ–‡æ¡£ç±»å‹
        "scrollPosition": 1024,           # æ»šåŠ¨ä½ç½®ï¼ˆåƒç´ ï¼‰æˆ–å­—ç¬¦ä½ç½®
        "scrollPercent": 45.5,            # æ»šåŠ¨è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰
        "currentPage": 5,                 # å½“å‰é¡µç 
        "displayMode": "continuous",      # æ˜¾ç¤ºæ¨¡å¼
        "timestamp": 1234567890000        # æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    }
    """
    try:
        data = request.get_json()
        doc_id = data.get("docId", "")
        
        if not doc_id:
            return jsonify({"status": "error", "message": "docId is required"}), 400
        
        progress_path = get_doc_progress_path(doc_id)
        
        # å‡†å¤‡è¿›åº¦æ•°æ®
        progress_data = {
            "docId": doc_id,
            "docType": data.get("docType", "unknown"),
            "scrollPosition": data.get("scrollPosition", 0),
            "scrollPercent": data.get("scrollPercent", 0),
            "currentPage": data.get("currentPage", 1),
            "displayMode": data.get("displayMode", "continuous"),
            "timestamp": int(__import__("time").time() * 1000)
        }
        
        # å†™å…¥è¿›åº¦æ–‡ä»¶
        with open(progress_path, "w", encoding="utf-8") as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            "status": "success",
            "message": f"Progress saved for document {doc_id}",
            "progressPath": str(progress_path)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/doc-progress/load", methods=["POST"])
def load_doc_progress():
    """åŠ è½½æ–‡æ¡£é˜…è¯»è¿›åº¦
    
    è¯·æ±‚ä½“:
    {
        "docId": "document-id"
    }
    """
    try:
        data = request.get_json()
        doc_id = data.get("docId", "")
        
        if not doc_id:
            return jsonify({"status": "error", "message": "docId is required"}), 400
        
        progress_path = get_doc_progress_path(doc_id)
        
        if progress_path.exists():
            with open(progress_path, "r", encoding="utf-8") as f:
                progress_data = json.load(f)
            
            return jsonify({
                "status": "success",
                "found": True,
                "progress": progress_data
            })
        else:
            return jsonify({
                "status": "success",
                "found": False,
                "progress": None,
                "message": "No progress found for this document"
            })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/doc-progress/delete", methods=["POST"])
def delete_doc_progress():
    """åˆ é™¤æ–‡æ¡£é˜…è¯»è¿›åº¦"""
    try:
        data = request.get_json()
        doc_id = data.get("docId", "")
        
        if not doc_id:
            return jsonify({"status": "error", "message": "docId is required"}), 400
        
        progress_path = get_doc_progress_path(doc_id)
        
        if progress_path.exists():
            progress_path.unlink()
            return jsonify({
                "status": "success",
                "message": f"Progress deleted for document {doc_id}"
            })
        else:
            return jsonify({
                "status": "success",
                "message": "No progress found to delete"
            })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/api/doc-progress/list", methods=["GET"])
def list_doc_progress():
    """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£é˜…è¯»è¿›åº¦"""
    try:
        if not DOC_PROGRESS_DIR.exists():
            return jsonify({
                "status": "success",
                "progresses": []
            })
        
        progresses = []
        for progress_file in DOC_PROGRESS_DIR.glob("*.progress.json"):
            with open(progress_file, "r", encoding="utf-8") as f:
                progress_data = json.load(f)
            progresses.append(progress_data)
        
        return jsonify({
            "status": "success",
            "progresses": progresses,
            "count": len(progresses)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500


@app.route("/")
def index():
    idx = Path(__file__).parent.parent / "static" / "index.html"
    if idx.exists():
        return send_file(str(idx))
    else:
        return jsonify({"status": "error", "message": "index.html not found", "path": str(idx)}), 500


@app.route("/static/pdf-viewer.html")
def pdf_viewer():
    """PDFæŸ¥çœ‹å™¨è·¯ç”± - ç¦ç”¨ç¼“å­˜ç¡®ä¿æ€»æ˜¯ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬"""
    viewer_path = Path(__file__).parent.parent / "static" / "pdf-viewer.html"
    if viewer_path.exists():
        response = send_file(str(viewer_path))
        response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        return response
    else:
        return jsonify({"status": "error", "message": "pdf-viewer.html not found"}), 404


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
